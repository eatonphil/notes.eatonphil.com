<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    
    <title>Writing a simple JSON parser | notes.eatonphil.com</title>
    <meta name="description" content="Writing a simple JSON parser" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/default.min.css" />
    
    <link rel="stylesheet" type="text/css" href="/style.css" />

    <link rel="alternate" type="application/rss+xml" href="/rss.xml" />
  </head>
  <body>
    <header>
      <div class="container">
        <div>
          <div class="row">
	    <a href="/" class="sm-link">
              Home
            </a>
	    <a href="/rss.xml" class="sm-link">
              RSS
            </a>

	    <div class="subscribe">
              <a href="https://docs.google.com/forms/d/e/1FAIpQLSchaYjB6mq0SHmFL_J1wbB7E4SwUk23Dja2K7mfjtYH5o48fw/viewform?usp=sf_link">
		Subscribe
              </a>
	    </div>
	  </div>

          <h2>May 6, 2018</h2>
          <h1>Writing a simple JSON parser</h1>
          <div class="row" style="padding-bottom: 5px">
            <div class="tags"><a href="/tags/json.html" class="tag">json</a><a href="/tags/parsing.html" class="tag">parsing</a><a href="/tags/python.html" class="tag">python</a></div>
          </div>
	</div>
      </div>
    </header>

    <div class="container">
      <div class="col-6">
        <p>Writing a JSON parser is one of the easiest ways to get familiar with
parsing techniques. The format is extremely simple. It's defined
recursively so you get a slight challenge compared to, say, parsing
<a href="https://en.wikipedia.org/wiki/Brainfuck">Brainfuck</a>; and you probably
already use JSON. Aside from that last point, parsing
<a href="https://en.wikipedia.org/wiki/S-expression">S-expressions</a> for Scheme
might be an even simpler task.</p>
<p>If you'd just like to see the code for the library, <code>pj</code>, <a href="https://github.com/eatonphil/pj">check it out
on Github</a>.</p>
<h3 id="what-parsing-is-and-(typically)-is-not">What parsing is and (typically) is not</h3><p>Parsing is often broken up into two stages: lexical analysis and
syntactic analysis. Lexical analysis breaks source input into the
simplest decomposable elements of a language called "tokens".
Syntactic analysis (often itself called "parsing") receives the list
of tokens and tries to find patterns in them to meet the language
being parsed.</p>
<p>Parsing does not determine semantic viability of an input
source. Semantic viability of an input source might include whether or
not a variable is defined before being used, whether a function is
called with the correct arguments, or whether a variable can be
declared a second time in some scope.</p>
<p class="note">
  There are, of course, always variations in how people choose to
  parse and apply semantic rules, but I am assuming a "traditional"
  approach to explain the core concepts.
</p><h4 id="the-json-library's-interface">The JSON library's interface</h4><p>Ultimately, there should be a <code>from_string</code> method that accepts a
JSON-encoded string and returns the equivalent Python dictionary.</p>
<p>For example:</p>
<pre><code>assert_equal(from_string('{"foo": 1}'),
             {"foo": 1})
</code></pre>
<h3 id="lexical-analysis">Lexical analysis</h3><p>Lexical analysis breaks down an input string into tokens. Comments and
whitespace are often discarded during lexical analysis so you are left
with a simpler input you can search for grammatical matches during the
syntactic analysis.</p>
<p>Assuming a simple lexical analyzer, you might iterate over all the
characters in an input string (or stream) and break them apart into
fundemental, <strong>non-recursively</strong> defined language constructs such as
integers, strings, and boolean literals. In particular, strings
<strong>must</strong> be part of the lexical analysis because you cannot throw away
whitespace without knowing that it is not part of a string.</p>
<p class="note">
  In a helpful lexer you keep track of the whitespace and comments
  you've skipped, the current line number and file you are in so that
  you can refer back to it at any stage in errors produced by analysis
  of the source. <a
  href="https://v8project.blogspot.com/2018/03/v8-release-66.html">The
  V8 Javascript engine recently became able to do reproduce the exact
  source code of a function.</a> This, at the very least, would need
  the help of a lexer to make possible.
</p><h4 id="implementing-a-json-lexer">Implementing a JSON lexer</h4><p>The gist of the JSON lexer will be to iterate over the input source
and try to find patterns of strings, numbers, booleans, nulls, or JSON
syntax like left brackets and left braces, ultimately returning
each of these elements as a list.</p>
<p>Here is what the lexer should return for an example input:</p>
<pre><code class="hljs python">assert_equal(lex(&#39;{&quot;foo&quot;: [1, 2, {&quot;bar&quot;: 2}]}&#39;),
             [&#39;{&#39;, &#39;foo&#39;, &#39;:&#39;, &#39;[&#39;, 1, &#39;,&#39;, 2, &#39;,&#39;, &#39;{&#39;, &#39;bar&#39;, &#39;:&#39;, 2, &#39;}&#39;, &#39;]&#39;, &#39;}&#39;])
</code></pre>
<p>Here is what this logic might begin to look like:</p>
<pre><code class="hljs python">def lex(string):
    tokens = []

    while len(string):
        json_string, string = lex_string(string)
        if json_string is not None:
            tokens.append(json_string)
            continue

        # TODO: lex booleans, nulls, numbers

        if string[0] in JSON_WHITESPACE:
            string = string[1:]
        elif string[0] in JSON_SYNTAX:
            tokens.append(string[0])
            string = string[1:]
        else:
            raise Exception(&#39;Unexpected character: {}&#39;.format(string[0]))

    return tokens
</code></pre>
<p>The goal here is to try to match strings, numbers, booleans, and nulls
and add them to the list of tokens. If none of these match, check if
the character is whitespace and throw it away if so. Otherwise store
it as a token if it is part of JSON syntax (like left
brackets). Finally throw an exception if the character/string didn't
match any of these patterns.</p>
<p>Let's extend the core logic here a little bit to support all the types
and add the function stubs.</p>
<pre><code class="hljs python">def lex_string(string):
    return None, string


def lex_number(string):
    return None, string


def lex_bool(string):
    return None, string


def lex_null(string):
    return None, string


def lex(string):
    tokens = []

    while len(string):
        json_string, string = lex_string(string)
        if json_string is not None:
            tokens.append(json_string)
            continue

        json_number, string = lex_number(string)
        if json_number is not None:
            tokens.append(json_number)
            continue

        json_bool, string = lex_bool(string)
        if json_bool is not None:
            tokens.append(json_bool)
            continue

        json_null, string = lex_null(string)
        if json_null is not None:
            tokens.append(None)
            continue

        if string[0] in JSON_WHITESPACE:
            string = string[1:]
        elif string[0] in JSON_SYNTAX:
            tokens.append(string[0])
            string = string[1:]
        else:
            raise Exception(&#39;Unexpected character: {}&#39;.format(string[0]))

    return tokens
</code></pre>
<h4 id="lexing-strings">Lexing strings</h4><p>For the <code>lex_string</code> function, the gist will be to check if the first
character is a quote. If it is, iterate over the input string until
you find an ending quote. If you don't find an initial quote, return
None and the original list. If you find an initial quote and an ending
quote, return the string within the quotes and the rest of the
unchecked input string.</p>
<pre><code class="hljs python">def lex_string(string):
    json_string = &#39;&#39;

    if string[0] == JSON_QUOTE:
        string = string[1:]
    else:
        return None, string

    for c in string:
        if c == JSON_QUOTE:
            return json_string, string[len(json_string)+1:]
        else:
            json_string += c

    raise Exception(&#39;Expected end-of-string quote&#39;)
</code></pre>
<h4 id="lexing-numbers">Lexing numbers</h4><p>For the <code>lex_number</code> function, the gist will be to iterate over the
input until you find a character that cannot be part of a number.
(This is, of course, a gross simplification, but being more accurate
will be left as an exercise to the reader.) After finding a character
that cannot be part of a number, either return a float or int if the
characters you've accumulated number more than 0. Otherwise return
None and the original string input.</p>
<pre><code class="hljs python">def lex_number(string):
    json_number = &#39;&#39;

    number_characters = [str(d) for d in range(0, 10)] + [&#39;-&#39;, &#39;e&#39;, &#39;.&#39;]

    for c in string:
        if c in number_characters:
            json_number += c
        else:
            break

    rest = string[len(json_number):]

    if not len(json_number):
        return None, string

    if &#39;.&#39; in json_number:
        return float(json_number), rest

    return int(json_number), rest
</code></pre>
<h4 id="lexing-booleans-and-nulls">Lexing booleans and nulls</h4><p>Finding boolean and null values is a very simple string match.</p>
<pre><code class="hljs python">def lex_bool(string):
    string_len = len(string)

    if string_len &gt;= TRUE_LEN and \
       string[:TRUE_LEN] == &#39;true&#39;:
        return True, string[TRUE_LEN:]
    elif string_len &gt;= FALSE_LEN and \
         string[:FALSE_LEN] == &#39;false&#39;:
        return False, string[FALSE_LEN:]

    return None, string


def lex_null(string):
    string_len = len(string)

    if string_len &gt;= NULL_LEN and \
       string[:NULL_LEN] == &#39;null&#39;:
        return True, string[NULL_LEN]

    return None, string
</code></pre>
<p>And now the lexer code is done! See the
<a href="https://github.com/eatonphil/pj/blob/master/pj/lexer.py">pj/lexer.py</a>
for the code as a whole.</p>
<h3 id="syntactic-analysis">Syntactic analysis</h3><p>The syntax analyzer's (basic) job is to iterate over a one-dimensional
list of tokens and match groups of tokens up to pieces of the language
according to the definition of the language. If, at any point during
syntactic analysis, the parser cannot match the current set of tokens up
to a valid grammar of the language, the parser will fail and possibly
give you useful information as to what you gave, where, and what it
expected from you.</p>
<h4 id="implementing-a-json-parser">Implementing a JSON parser</h4><p>The gist of the JSON parser will be to iterate over the tokens
received after a call to <code>lex</code> and try to match the tokens to objects,
lists, or plain values.</p>
<p>Here is what the parser should return for an example input:</p>
<pre><code class="hljs python">tokens = lex(&#39;{&quot;foo&quot;: [1, 2, {&quot;bar&quot;: 2}]}&#39;)
assert_equal(tokens,
             [&#39;{&#39;, &#39;foo&#39;, &#39;:&#39;, &#39;[&#39;, 1, &#39;,&#39;, 2, &#39;{&#39;, &#39;bar&#39;, &#39;:&#39;, 2, &#39;}&#39;, &#39;]&#39;, &#39;}&#39;])
assert_equal(parse(tokens),
             {&#39;foo&#39;: [1, 2, {&#39;bar&#39;: 2}]})
</code></pre>
<p>Here is what this logic might begin to look like:</p>
<pre><code class="hljs python">def parse_array(tokens):
    return [], tokens

def parse_object(tokens):
    return {}, tokens

def parse(tokens):
    t = tokens[0]

    if t == JSON_LEFTBRACKET:
        return parse_array(tokens[1:])
    elif t == JSON_LEFTBRACE:
        return parse_object(tokens[1:])
    else:
        return t, tokens[1:]
</code></pre>
<p>A key structural difference between this lexer and parser is that the
lexer returns a one-dimensional array of tokens. Parsers are often
defined recursively and returns a recursive, tree-like object. Since
JSON is a data serialization format instead of a language, the parser
should produce objects in Python rather than a syntax tree on which
you could perform more analysis (or code generation in the case of a
compiler).</p>
<p>And, again, the benefit of having the lexical analysis happen
independent from the parser is that both pieces of code are simpler
and concerned with only specific elements.</p>
<h4 id="parsing-arrays">Parsing arrays</h4><p>Parsing arrays is a matter of parsing array members and expecting a
comma token between them or a right bracket indicating the end
of the array.</p>
<pre><code class="hljs python">def parse_array(tokens):
    json_array = []

    t = tokens[0]
    if t == JSON_RIGHTBRACKET:
        return json_array, tokens[1:]

    while True:
        json, tokens = parse(tokens)
        json_array.append(json)

        t = tokens[0]
        if t == JSON_RIGHTBRACKET:
            return json_array, tokens[1:]
        elif t != JSON_COMMA:
            raise Exception(&#39;Expected comma after object in array&#39;)
        else:
            tokens = tokens[1:]

    raise Exception(&#39;Expected end-of-array bracket&#39;)
</code></pre>
<h4 id="parsing-objects">Parsing objects</h4><p>Parsing objects is a matter of parsing a key-value pair internally
separated by a colon and externally separated by a comma until you
reach the end of the object.</p>
<pre><code class="hljs python">def parse_object(tokens):
    json_object = {}

    t = tokens[0]
    if t == JSON_RIGHTBRACE:
        return json_object, tokens[1:]

    while True:
        json_key = tokens[0]
        if type(json_key) is str:
            tokens = tokens[1:]
        else:
            raise Exception(&#39;Expected string key, got: {}&#39;.format(json_key))

        if tokens[0] != JSON_COLON:
            raise Exception(&#39;Expected colon after key in object, got: {}&#39;.format(t))

        json_value, tokens = parse(tokens[1:])

        json_object[json_key] = json_value

        t = tokens[0]
        if t == JSON_RIGHTBRACE:
            return json_object, tokens[1:]
        elif t != JSON_COMMA:
            raise Exception(&#39;Expected comma after pair in object, got: {}&#39;.format(t))

        tokens = tokens[1:]

    raise Exception(&#39;Expected end-of-object brace&#39;)
</code></pre>
<p>And now the parser code is done! See the
<a href="https://github.com/eatonphil/pj/blob/master/pj/parser.py">pj/parser.py</a>
for the code as a whole.</p>
<h3 id="unifying-the-library">Unifying the library</h3><p>To provide the ideal interface, create the <code>from_string</code> function
wrapping the <code>lex</code> and <code>parse</code> functions.</p>
<pre><code class="hljs python">def from_string(string):
    tokens = lex(string)
    return parse(tokens)[0]
</code></pre>
<p>And the library is complete! (ish). Check out the <a href="https://github.com/eatonphil/pj">project on
Github</a> for the full implementation
including basic testing setup.</p>
<h3 id="appendix-a:-single-step-parsing">Appendix A: Single-step parsing</h3><p>Some parsers choose to implement lexical and syntactic analysis in one
stage. For some languages this can simplify the parsing stage
entirely. Or, in more powerful languages like Common Lisp, it can
allow you to dynamically extend the lexer and parser in one step with
<a href="https://gist.github.com/chaitanyagupta/9324402">reader macros</a>.</p>
<p class="note">
  I wrote this library in Python to make it more accessible to
  a larger audience. However, many of the techniques used are more
  amenable to languages with pattern matching and support for monadic
  operations -- like Standard ML. If you are curious what this same
  code would look like in Standard ML, check out the <a
  href="https://github.com/eatonphil/ponyo/blob/master/src/Encoding/Json.sml">JSON
  code in Ponyo</a>.
</p><p><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I wrote a short post (and a corresponding Python library) explaining lexing and parsing with JSON <a href="https://t.co/3yEZlcU6i5">https://t.co/3yEZlcU6i5</a> <a href="https://t.co/FbksvUO9aT">https://t.co/FbksvUO9aT</a> <a href="https://twitter.com/hashtag/json?src=hash&amp;ref_src=twsrc%5Etfw">#json</a> <a href="https://twitter.com/hashtag/python?src=hash&amp;ref_src=twsrc%5Etfw">#python</a></p>&mdash; Phil Eaton (@phil_eaton) <a href="https://twitter.com/phil_eaton/status/993251098931712005?ref_src=twsrc%5Etfw">May 6, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<style>.feedback{display:initial;}</style>
	<div class="feedback">
	  <h4>Feedback</h4>
	  As always,
	  please <a href="mailto:phil@eatonphil.com">email</a>
	  or <a href="https://twitter.com/phil_eaton">tweet me</a>
	  with questions, corrections, or ideas!
	</div>
      </div>
    </div>

    <footer>
      <div class="container">
	<div>
	  <div class="row">
	    <a href="/" class="sm-link">
              Home
            </a>
	    <a href="/rss.xml" class="sm-link">
              RSS
            </a>

	    <div class="subscribe">
              <a href="https://docs.google.com/forms/d/e/1FAIpQLSchaYjB6mq0SHmFL_J1wbB7E4SwUk23Dja2K7mfjtYH5o48fw/viewform?usp=sf_link">
		Subscribe
              </a>
	    </div>
	  </div>
	  <div class="feedback">
	    <p>Frequent Topics</p>
	    <div class="tags"><a href="/tags/javascript.html" class="tag">javascript (21)</a><a href="/tags/compilers.html" class="tag">compilers (13)</a><a href="/tags/parsing.html" class="tag">parsing (13)</a><a href="/tags/golang.html" class="tag">golang (10)</a><a href="/tags/postgres.html" class="tag">postgres (9)</a><a href="/tags/management.html" class="tag">management (8)</a><a href="/tags/lisp.html" class="tag">lisp (8)</a><a href="/tags/interpreters.html" class="tag">interpreters (8)</a><a href="/tags/databases.html" class="tag">databases (7)</a><a href="/tags/sql.html" class="tag">sql (7)</a><a href="/tags/python.html" class="tag">python (6)</a><a href="/tags/typescript.html" class="tag">typescript (5)</a><a href="/tags/x86-amd64.html" class="tag">x86/amd64 (5)</a><a href="/tags/linux.html" class="tag">linux (5)</a><a href="/tags/communication.html" class="tag">communication (5)</a><a href="/tags/json.html" class="tag">json (5)</a><a href="/tags/docker.html" class="tag">docker (4)</a><a href="/tags/books.html" class="tag">books (4)</a><a href="/tags/learning.html" class="tag">learning (4)</a><a href="/tags/d.html" class="tag">d (4)</a></div>
	  </div>
	</div>
      </div>
    </footer>

    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-58109156-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-58109156-2');
    </script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>
